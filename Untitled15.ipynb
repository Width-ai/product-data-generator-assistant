{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUzfgiXJ5fCP"
      },
      "outputs": [],
      "source": [
        "## check out https://platform.openai.com/docs/assistants/tools/file-search\n",
        "## This is not a completed doc, but a compilation of code required with various options for each step.\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "assistant = client.beta.assistants.create(\n",
        "  name=\"Product Data Generator Assistant\",\n",
        "  instructions: '''You are a product catalog expert focused on writing product information for new & existing products.\n",
        "\n",
        "Company online statement:\n",
        "\"Fun for All Promise\"\n",
        "\n",
        "\"We create the world’s most outrageous apparel because we believe fun is something that everyone deserves to experience. Our mission is to design products that turn every occasion into unforgettable moments. But the way we see it, life is about more than just the celebrations, it’s about celebrating each other along the way.\"\n",
        "\n",
        "\n",
        "Rules:\n",
        "ALWAYS include the following fields when generating new product data.\n",
        "\n",
        "- Product title\n",
        "- Description\n",
        "-Price\n",
        "\n",
        "''',\n",
        "  model=\"gpt-4o\",\n",
        "  tools=[{\"type\": \"file_search\"}],\n",
        ")\n",
        "\n",
        "\n",
        "# Create a vector store caled \"Financial Statements\"\n",
        "vector_store = client.beta.vector_stores.create(name=\"Products\")\n",
        "\n",
        "# Ready the files for upload to OpenAI\n",
        "file_paths = [\"product files\", \"product files\"]\n",
        "file_streams = [open(path, \"rb\") for path in file_paths]\n",
        "\n",
        "# Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
        "# and poll the status of the file batch for completion.\n",
        "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
        "  vector_store_id=vector_store.id, files=file_streams\n",
        ")\n",
        "\n",
        "# You can print the status and the file counts of the batch to see the result of this operation.\n",
        "print(file_batch.status)\n",
        "print(file_batch.file_counts)\n",
        "\n",
        "\n",
        "\n",
        "# update your assistant\n",
        "assistant = client.beta.assistants.update(\n",
        "  assistant_id=assistant.id,\n",
        "  tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# can also do this like this:\n",
        "message_file = client.files.create(\n",
        "  file=open(\"example.pdf\", \"rb\"), purpose=\"assistants\"\n",
        ")\n",
        "\n",
        "# Create a thread and attach the file to the message\n",
        "thread = client.beta.threads.create(\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Create a spicy new product based on the provided image for our new Christmas collection. Focus on quirky!\",\n",
        "      # Attach the new file to the message.\n",
        "      \"attachments\": [\n",
        "        { \"file_id\": message_file.id, \"tools\": [{\"type\": \"file_search\"}] }\n",
        "      ],\n",
        "    }\n",
        "  ]\n",
        ")\n",
        "\n",
        "# The thread now has a vector store with that file in its tool resources.\n",
        "print(thread.tool_resources.file_search)\n",
        "\n",
        "\n",
        "class EventHandler(AssistantEventHandler):\n",
        "    @override\n",
        "    def on_text_created(self, text) -> None:\n",
        "        print(f\"\\nassistant > \", end=\"\", flush=True)\n",
        "\n",
        "    @override\n",
        "    def on_tool_call_created(self, tool_call):\n",
        "        print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
        "\n",
        "    @override\n",
        "    def on_message_done(self, message) -> None:\n",
        "        # print a citation to the file searched\n",
        "        message_content = message.content[0].text\n",
        "        annotations = message_content.annotations\n",
        "        citations = []\n",
        "        for index, annotation in enumerate(annotations):\n",
        "            message_content.value = message_content.value.replace(\n",
        "                annotation.text, f\"[{index}]\"\n",
        "            )\n",
        "            if file_citation := getattr(annotation, \"file_citation\", None):\n",
        "                cited_file = client.files.retrieve(file_citation.file_id)\n",
        "                citations.append(f\"[{index}] {cited_file.filename}\")\n",
        "\n",
        "        print(message_content.value)\n",
        "        print(\"\\n\".join(citations))\n",
        "\n",
        "\n",
        "# Then, we use the stream SDK helper\n",
        "# with the EventHandler class to create the Run\n",
        "# and stream the response.\n",
        "\n",
        "with client.beta.threads.runs.stream(\n",
        "    thread_id=thread.id,\n",
        "    assistant_id=assistant.id,\n",
        "    instructions=\"Please address the user as Jane Doe. The user has a premium account.\",\n",
        "    event_handler=EventHandler(),\n",
        ") as stream:\n",
        "    stream.until_done()"
      ]
    }
  ]
}